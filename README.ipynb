{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dftest.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XuB012bc6aJO",
        "6saQvRKL9m40",
        "gHXjmsGKT7jQ",
        "kokZWf64Xgxb",
        "noQlBl70V28e",
        "8H2EO7QFYvzG",
        "BbFxVrBZbdEg",
        "LEhOCoJilvDQ",
        "m63VkDCMk52c",
        "X4fE2XLdVUcb",
        "jK0Z87V8lo0g",
        "qxeWlk-gNUt8",
        "QzadkuQzOJZ_",
        "D8ZrKBcDOGvp",
        "OwOg6nLIYQd0",
        "81bH-58bKp7p",
        "56PKgkVKMBTs",
        "Da2fQ2DRQ5_s",
        "pKjsYCC_RJXD",
        "BHB2jGaWeS_6",
        "ZQ7OVFkTdh0J",
        "-kNaMSBRdtQ3",
        "bChoJdQAeDWQ",
        "4DyjSHfZeTwH",
        "yDvfBLA8eyej",
        "glFkOj8iw2wc",
        "Gi0FE0_uw9aR",
        "2Q_rLPHZxHtf",
        "J2Ocsh8FZ7eu",
        "zMX0ijvHgT8J",
        "DKp6tbeeMBW_",
        "wjjDXplthJ8Y",
        "1eBsaSGjqhQf",
        "BHTZTIaUqkxW",
        "KBl4eSz4qpuR",
        "z2dFT9XpqxRs",
        "jQiTmUr5q8bM",
        "QnbCdhrarVOi",
        "kQXgU1ZDrbLw",
        "rfNpXZaetROM",
        "euiyX-Y2UGi4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "XuB012bc6aJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Real data is messy. If it's because of changes in standards, human error, or just because the real data points are messy, when taking real data from insitutions that were usually not keeping out around for the purposes of data science, we tend to encounter inconsistent formatting, missing values, duplicates, inconsistent typing, and other issues.\n",
        "\n",
        "`dftest` (inspired by `pytest`) is a project aims to give data scientists tools to detect problematic data which may lead to unexpected results, and loctae these rows and columns which may need to be removed or require additional cleaning."
      ],
      "metadata": {
        "id": "otrHc-OG6gs6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation & Setup"
      ],
      "metadata": {
        "id": "6saQvRKL9m40"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_P2VLjz5XR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e1bc0a0-1e4d-4802-ffb0-d04b0032f116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /tmp/tmp.789Q3dhBrV\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "    Preparing wheel metadata: started\n",
            "    Preparing wheel metadata: finished with status 'done'\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from dftest==0.2.1) (1.21.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from dftest==0.2.1) (3.2.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from dftest==0.2.1) (0.3.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from dftest==0.2.1) (0.11.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from dftest==0.2.1) (1.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from dftest==0.2.1) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->dftest==0.2.1) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->dftest==0.2.1) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->dftest==0.2.1) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->dftest==0.2.1) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->dftest==0.2.1) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->dftest==0.2.1) (2018.9)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn->dftest==0.2.1) (1.4.1)\n",
            "Building wheels for collected packages: dftest\n",
            "  Building wheel for dftest (PEP 517): started\n",
            "  Building wheel for dftest (PEP 517): finished with status 'done'\n",
            "  Created wheel for dftest: filename=dftest-0.2.1-py3-none-any.whl size=18667 sha256=bb823dc348bc851e452b3ad99a2219c7a75007371af21952d2c48435e098a86d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-57y9cwgc/wheels/10/27/81/71304e43a272489a26c30a53433bab66afb802486e75eb63f9\n",
            "Successfully built dftest\n",
            "Installing collected packages: dftest\n",
            "  Attempting uninstall: dftest\n",
            "    Found existing installation: dftest 0.2.1\n",
            "    Uninstalling dftest-0.2.1:\n",
            "      Successfully uninstalled dftest-0.2.1\n",
            "Successfully installed dftest-0.2.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into '/tmp/tmp.789Q3dhBrV'...\n",
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n"
          ]
        }
      ],
      "source": [
        "# !pip3 install --index-url https://test.pypi.org/simple/ --upgrade  dftestbash\n",
        "\n",
        "%%bash\n",
        "builddir=$(mktemp -d)\n",
        "git clone https://github.com/TheAllSeeing/PandasTestingSuite $builddir\n",
        "pip3 install $builddir"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Packages we'll need for this demonstration\n",
        "import pandas as pd # Required for working with dftest\n",
        "import numpy as np # Will be used for randomly populating dataframes\n",
        "\n",
        "from dftest import DFTests, tests"
      ],
      "metadata": {
        "id": "9IXPR5BMBfn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demonstration 1: ensuring positive numbers"
      ],
      "metadata": {
        "id": "yL0edr9bAviv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at how this tool can be used with some very basic data frames."
      ],
      "metadata": {
        "id": "whFouuvFA0hl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 0: get a dataframe to test"
      ],
      "metadata": {
        "id": "gHXjmsGKT7jQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Of course, in order to test the integrity of _any_ data, we first need to have it.\n",
        "\n",
        "For this minimal example, we're create our own random dataset with 4 columns of integers between 0 and 100 and a fifth column containing lower case letters."
      ],
      "metadata": {
        "id": "C8Zykh4eUYAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df =  pd.DataFrame(np.random.randint(0, 100, size=(100, 4)), columns=list('ABCD'))\n",
        "df['E'] = np.random.choice([chr(i) for i in range(97, 121)], size=100)\n",
        "df.to_csv('example.csv', index_label='Index')"
      ],
      "metadata": {
        "id": "Vi6WEgUVBYNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('example.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "hYGs8P_xa1Ba",
        "outputId": "cfc90440-e875-45c0-89f9-83663629dab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-388094fa-6ab3-461a-8082-615a429ec317\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>90</td>\n",
              "      <td>75</td>\n",
              "      <td>55</td>\n",
              "      <td>k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>39</td>\n",
              "      <td>8</td>\n",
              "      <td>44</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>42</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>89</td>\n",
              "      <td>15</td>\n",
              "      <td>47</td>\n",
              "      <td>j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>85</td>\n",
              "      <td>42</td>\n",
              "      <td>62</td>\n",
              "      <td>f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>18</td>\n",
              "      <td>80</td>\n",
              "      <td>18</td>\n",
              "      <td>83</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>7</td>\n",
              "      <td>84</td>\n",
              "      <td>69</td>\n",
              "      <td>19</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>55</td>\n",
              "      <td>20</td>\n",
              "      <td>16</td>\n",
              "      <td>40</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>11</td>\n",
              "      <td>99</td>\n",
              "      <td>72</td>\n",
              "      <td>28</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>71</td>\n",
              "      <td>96</td>\n",
              "      <td>69</td>\n",
              "      <td>42</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-388094fa-6ab3-461a-8082-615a429ec317')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-388094fa-6ab3-461a-8082-615a429ec317 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-388094fa-6ab3-461a-8082-615a429ec317');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Index   A   B   C   D  E\n",
              "0       0  51  90  75  55  k\n",
              "1       1  60  39   8  44  n\n",
              "2       2  42  33   1  59  d\n",
              "3       3  12  89  15  47  j\n",
              "4       4  25  85  42  62  f\n",
              "..    ...  ..  ..  ..  .. ..\n",
              "95     95  18  80  18  83  c\n",
              "96     96   7  84  69  19  p\n",
              "97     97  55  20  16  40  u\n",
              "98     98  11  99  72  28  d\n",
              "99     99  71  96  69  42  c\n",
              "\n",
              "[100 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: think about something to test"
      ],
      "metadata": {
        "id": "kokZWf64Xgxb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this example, let's say we'd like to make sure all the values in column B are positive."
      ],
      "metadata": {
        "id": "-Du5Z0G7XlWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do we want a _boolean_ or _index_ test?\n",
        "<a name=\"test-types\"></a>\n",
        "`dftest` tests can be any function that takes in a dataframe and output either:\n",
        "- A boolean value indicating column validity (\"Boolean Test\").\n",
        "- A list of hashable values (usually ints) indicating indexes of invalid rows (\"Index Test\").\n",
        "\n",
        "As a rule of thumb, if you collect more information (i.e return row indexes instead of just true/false value), you will get more extensive analytics.\n",
        " \n",
        "We might not care much for extensive analytics though, and just want to ensure a large enough portion of the column is valid. So for this example, we'll define a **boolean test** which ensures at least 95% of the column is positive."
      ],
      "metadata": {
        "id": "RhKCYIyxCBhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: define your test"
      ],
      "metadata": {
        "id": "noQlBl70V28e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test functions must start with the prefix `dftest` in order to be recognized. the package supports snake_case, PascalCase and camelCase (`DFTestCheck`, `dftest_check`, `df_test_check`, `DfTestCheck`, `dfTestCheck`, etc.)\n",
        "\n",
        "Excpeting the stated constraints on parameters and return value, a test function can be any python function, regardless of where or how it's defined.\n",
        "\n",
        "```python\n",
        "# Option 1: lambda\n",
        "dftest_b_positive = lambda df: sum(1 for cell in dataframe['B'] if cell > 0) / len(df.index) >= 0.95\n",
        "\n",
        "# Option 2: def syntax\n",
        "def dftest_b_positive(dataframe: pd.DataFrame):\n",
        "  valid_count = sum(1 for cell in dataframe['B'] if cell > 0)\n",
        "  row_count = len(dataframe.index)\n",
        "  res = valid_count / row_count >= 0.95\n",
        "  return res\n",
        "\n",
        "# Option 3: whatever you feel like!\n",
        "```"
      ],
      "metadata": {
        "id": "TYTFabjIYxn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: save the test in a file"
      ],
      "metadata": {
        "id": "8H2EO7QFYvzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Much like `pytest`, the `dftest` command runs on python files containing test functions (though unlike `pytest`, they operate on some dataset that can be external to the code). "
      ],
      "metadata": {
        "id": "rU_1P3uoaCAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests.py\n",
        "def dftest_b_positive(dataframe):\n",
        "  valid_count = dataframe['B'].apply(lambda x: x > 0).sum()\n",
        "  row_count = len(dataframe.index)\n",
        "  res = valid_count / row_count >= 0.95\n",
        "  return res"
      ],
      "metadata": {
        "id": "4ZnfW_b_EQJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2068e23b-4f72-4ca0-95c9-ab337a15a1ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: running the tests:"
      ],
      "metadata": {
        "id": "JK-GPe_WbA-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the most basic usage of the `dftest` command, we specify a dataset file (in CSV, TSV, Excel or JSON formats) and a list of files containing test functions. Note that each "
      ],
      "metadata": {
        "id": "dxaggfZMEojd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --dataframe example.csv --files tests.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boXW-cRYGc8L",
        "outputId": "df55d9c5-bbd7-4423-f5bb-4ff2fdcdcd62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_b_positive)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "Columns Tested: 1/6 (17%).\n",
            "Columns valid: 1/1 (100.0%).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: looking at dataframe results"
      ],
      "metadata": {
        "id": "BbFxVrBZbdEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can add certain flags to print more information or show analytics.\n",
        "\n",
        "- `--print` or `-p` prints a summary of coverage and details results for individual tests in invalid columns. Runs by default if no graph options are specified.\n",
        "\n",
        "- `--graph` or `-g` opens pyplot graphs according to its arguments\n",
        "    - `validity` will create and return a pyplot figure with a 1D heatmap of \n",
        "    the columns by validity. \n",
        "    - `summary` will create and return a pyplot figure with pie charts showing \n",
        "    the amount of columns tested and amount of columns valid.\n",
        "    - `coverage` will create and return a binary-colored heatmap showing which \n",
        "    columns were tested.\n",
        "\n"
      ],
      "metadata": {
        "id": "H3oKXIRqhiH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By running the commands below you can generate a heatmap of the validity for each column. You should see a green bar for column B and 3 white bars for columns A, B and C, marking that they are untested (\"lack coverage\"). \n",
        "\n",
        "The final bar represents the Dataframe, and should be marked valid as well. \n",
        "\n",
        "In general, it would be marked invalid for any failed test, though it is unaffected by uncovered columns."
      ],
      "metadata": {
        "id": "wLHzGKCujJcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --dataframe example.csv --files tests.py --print --graph validity summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGS1TTD3fZRC",
        "outputId": "ed536dd5-213d-466f-c3be-87ee6bc625a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_b_positive)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "Columns Tested: 1/6 (17%).\n",
            "Columns valid: 1/1 (100.0%).\n",
            "\n",
            "<Figure size 640x480 with 2 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "___A small note:___ graphing methods create and return pyplot figures, which causes Colab to display the graphs twice, once when plotted and another one when it returns. To avoid this you can simply put the returned figure into a variable, as is done in this notebook.\n",
        "\n",
        "In a traditional run, the graphs would not be displayed until pyplot.show() is called. For this purpose, the results class contains a pointer to the pyplot module, such that you can call `results.plt.show()`."
      ],
      "metadata": {
        "id": "PSnZ2mmbPEnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: looking at column results"
      ],
      "metadata": {
        "id": "LEhOCoJilvDQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can show results for a specific column using the `--column` option (short version `-c`). Column results provide a slightly different collection of graphs - \n",
        "\n",
        "- There is no `coverage` graph\n",
        "- `tests` graph displays bar charts comparing sucess of different Index tests. \n",
        "- `validity` graph displays a heat map of tests success.\n",
        "- `summary` only displays a pie chart of test success rate."
      ],
      "metadata": {
        "id": "j7F1Wfh-mZje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --dataframe example.csv --files tests.py --column B --print --graph validity summary"
      ],
      "metadata": {
        "id": "PvtT7pB0mFOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c38b07-2912-49a6-bbec-7be963deb223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_b_positive)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "--- B ---\n",
            "Test #01: dftest_b_positive: Success\n",
            "\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Saving results to file"
      ],
      "metadata": {
        "id": "m63VkDCMk52c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Of course, we don't want to run the tests again every time we want to look at the results. For this reason, you can use the `--dump` option to specify a file to save the results to."
      ],
      "metadata": {
        "id": "QgksV4sUllor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --dataframe example.csv --files tests.py --dump results.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_Kqnd7rlpkw",
        "outputId": "c826dec7-02c7-4f6f-cece-96c16bc9fb59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_b_positive)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "Columns Tested: 1/6 (17%).\n",
            "Columns valid: 1/1 (100.0%).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then you can load the results using the `--results` option, omitting the `--dataframe` and `--files` parameters."
      ],
      "metadata": {
        "id": "KZhcQ6dWlyWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest  --results results.bin --print"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZWQabk-mDai",
        "outputId": "95281e2f-610c-4370-e7fb-83566ddb5ee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/dftest\", line 68, in <module>\n",
            "    results = dill.load(dumpfile)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/dill/_dill.py\", line 313, in load\n",
            "    return Unpickler(file, ignore=ignore, **kwds).load()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/dill/_dill.py\", line 525, in load\n",
            "    obj = StockUnpickler.load(self)\n",
            "EOFError: Ran out of input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --results results.bin --column B --graph validity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPIJoPZrn1eX",
        "outputId": "74ab31bc-aaf1-43a4-d09f-b682af55ce37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/dftest\", line 68, in <module>\n",
            "    results = dill.load(dumpfile)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/dill/_dill.py\", line 313, in load\n",
            "    return Unpickler(file, ignore=ignore, **kwds).load()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/dill/_dill.py\", line 525, in load\n",
            "    obj = StockUnpickler.load(self)\n",
            "EOFError: Ran out of input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**important:** results are saved in the [pickle](https://docs.python.org/3/library/pickle.html#module-pickle) format. It is possible to constrct a maliciouys pickle file which will execute arbitrary code when loaded; _only load files you trust._"
      ],
      "metadata": {
        "id": "vKY5RS4xsWte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8: seeing the test is working"
      ],
      "metadata": {
        "id": "X4fE2XLdVUcb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's put some invalid values in B, just to see that our test is really detecting invalid rows. "
      ],
      "metadata": {
        "id": "goOotcVzVZWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('example.csv', index_col=0)\n",
        "df.loc[:5, 'B'] *= -1\n",
        "df.to_csv('example.csv')"
      ],
      "metadata": {
        "id": "IZvoEifE7XUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --dataframe example.csv --files tests.py  --print --graph validity"
      ],
      "metadata": {
        "id": "DLTYEMUU7e5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579cfcf5-6055-4132-972b-7ddfdbfa5669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_b_positive)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "Columns Tested: 1/6 (17%).\n",
            "Columns valid: 0/1 (0.0%).\n",
            "\n",
            "--- Column 3: B ---\n",
            "Test #01: dftest_b_positive: Failure\n",
            "\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems to work well enough. Notice how info about the tests of invalid columns are printed after the summary."
      ],
      "metadata": {
        "id": "tUW_uVI78mn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "_What happens if we put in values that the test is not meant to check,_ like missing values or incorrect types? The short answer: it's up to you. More info can be found in [Demonstration 4](#demonstration-4) and [Demonstration 6](#demonstration-6)."
      ],
      "metadata": {
        "id": "7XNpxNeyZHWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!which dftest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkvIEuzywRkd",
        "outputId": "14970aac-59a5-492b-8df2-6d2f285b77ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/dftest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demonstration 2: generalizing tests"
      ],
      "metadata": {
        "id": "jK0Z87V8lo0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Which columns is this test applicable to?"
      ],
      "metadata": {
        "id": "qxeWlk-gNUt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test we made is applicable to more than column B. All of our numeric columns here are supposed to be positive. \n",
        "\n",
        "However, since we each function can only return a single True/False value, we would need to create different test functions for each of the columns we would want to get results for.  How might we "
      ],
      "metadata": {
        "id": "VXFzRjmcCjLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Understanding Generic Tests"
      ],
      "metadata": {
        "id": "QzadkuQzOJZ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a solution to this problem, `dftests` supports tests that rather than just run on a dataframe, runs on __some column__ in a dataframe."
      ],
      "metadata": {
        "id": "gikoWhXizPFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "For example:\n",
        "\n",
        "```python\n",
        "def dftest_positive(column: str, dataframe: pd.DataFrame):\n",
        "  valid_count = dataframe[column].apply(lambda x: x > 0).sum()\n",
        "  row_count = len(dataframe.index)\n",
        "  res = valid_count / row_count >= 0.95\n",
        "  return res\n",
        "```"
      ],
      "metadata": {
        "id": "sCNuu_7_iLTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rather than make a test that runs on a dataframe, we made a test that runs on a __some column__ and a dataframe.\n",
        "\n",
        "In this library, we call tests that take in _some column_ as \"generic\" tests, and they are automatically recognized by the `dftest` command.\n",
        "\n",
        "By default, when dftest runs into a generic test, it applies it to each column in the dataframe."
      ],
      "metadata": {
        "id": "CPw_eLqwp2KW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Important:*** _the order of parmeters is significant. trying to add a function that takes (dataframe, column) will cause error and unexpected behaviour_"
      ],
      "metadata": {
        "id": "I8MYj_zPEKji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Tests options & Understanding how to test specific columns"
      ],
      "metadata": {
        "id": "D8ZrKBcDOGvp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a general rule, you can configure the way `dftest` treats a test funciton with the `dftest.options` decorator.\n",
        "\n",
        "For example, the test delinated above should not run on the string column E. We can achieve this in a numer of ways using the `dftest.options` decorator:\n",
        "\n",
        "```python\n",
        "# Specifying columns for the test to run on\n",
        "\n",
        "# by hand\n",
        "@dftest.options(include=['A', 'B', 'C', 'D'])\n",
        "def dftest_positive(column: str, dataframe: pd.DataFrame):\n",
        "  valid_count = sum(1 for cell in dataframe[column] if cell > 0)\n",
        "  row_count = len(dataframe.index)\n",
        "  res = valid_count / row_count >= 0.95\n",
        "  return res\n",
        "\n",
        "# by dtype\n",
        "@dftest.options(include_dtypes=[int])\n",
        "def dftest_positive(column: str, dataframe: pd.DataFrame):\n",
        "  valid_count = sum(1 for cell in dataframe[column] if cell > 0)\n",
        "  row_count = len(dataframe.index)\n",
        "  res = valid_count / row_count >= 0.95\n",
        "  return res\n",
        "```\n",
        "```python\n",
        "# Specifying columns for the test not to run on\n",
        "@dftest.options(exclude=['E'])\n",
        "def dftest_positive(column: str, dataframe: pd.DataFrame):\n",
        "  valid_count = sum(1 for cell in dataframe[column] if cell > 0)\n",
        "  row_count = len(dataframe.index)\n",
        "  res = valid_count / row_count >= 0.95\n",
        "  return res\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "F73pmKR1q0pT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decorators only work right above a function definition using `def`. Since you may want to import tests, use lambda exressions and so on, a function `declare_options` is also provided, which you can run on any callable attribute to define its optons.\n",
        "\n",
        "For example, the following test will check `int` and `float` columns for numbers bigger thana 1,000,000:\n",
        "\n",
        "```python\n",
        "import dftests\n",
        "\n",
        "dftest_big = lambda col, df: df[col].apply(lambda x: x > 1_000_00)\n",
        "dftests.declare_options(dftest_int, include_dtypes=[int, float)\n",
        "```"
      ],
      "metadata": {
        "id": "DQsNyjwQSaZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: putting it together:"
      ],
      "metadata": {
        "id": "OwOg6nLIYQd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests.py\n",
        "import dftest\n",
        "from pandas import DataFrame # for the type hint\n",
        "\n",
        "@dftest.options(include_dtypes=[int])\n",
        "def dftest_positive(column: str, dataframe: DataFrame):\n",
        "  valid_count = sum(1 for cell in dataframe[column] if cell > 0)\n",
        "  row_count = len(dataframe.index)\n",
        "  res = valid_count / row_count >= 0.95\n",
        "  return res"
      ],
      "metadata": {
        "id": "Ytw0hrW21cK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f157f4c-e2df-40a3-b3f9-7893059316f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice we are overwriting the test file rather than appending it, since we want to replace the previous test."
      ],
      "metadata": {
        "id": "0tBHRq4Cu5XG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: seeing the results:"
      ],
      "metadata": {
        "id": "81bH-58bKp7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --dataframe example.csv --files tests.py --print --graph validity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-TPO4lL1FoU",
        "outputId": "c6eeaf04-aff2-4cd7-c8e1-73b9b0d23ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_positive — A)\n",
            "\u001b[F\u001b[KTesting 20% (#2: dftest_positive — Index)\n",
            "\u001b[F\u001b[KTesting 40% (#3: dftest_positive — D)\n",
            "\u001b[F\u001b[KTesting 60% (#4: dftest_positive — C)\n",
            "\u001b[F\u001b[KTesting 80% (#5: dftest_positive — B)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "Columns Tested: 5/6 (83%).\n",
            "Columns valid: 4/5 (80.0%).\n",
            "\n",
            "--- Column 3: B ---\n",
            "Test #01: dftest_positive — B: Failure\n",
            "\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demonstration 3: Index Tests"
      ],
      "metadata": {
        "id": "56PKgkVKMBTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: create an index test and add it"
      ],
      "metadata": {
        "id": "Da2fQ2DRQ5_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might be interested in getting more information out of your tests. As mentioned, one way to do this is to use _Index Tests_, which return an index of valid and invalid values.\n",
        "\n",
        "Index Tests may return either\n",
        "1. An iterable containing indexes for invalid rows.\n",
        "1. An array or series with boolean values for each series\n",
        "\n",
        "```python\n",
        "# Option 1\n",
        "def dftest_positive(col, df):\n",
        "  return [i for i, cell in enumerate(df[col]) if cell > 0]\n",
        "\n",
        "# Option 2\n",
        "def dftest_positive(col, df):\n",
        "  return df[col].apply(lambda x: x > 0)\n",
        "```"
      ],
      "metadata": {
        "id": "ISnZvsksMPFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests.py\n",
        "import dftest\n",
        "\n",
        "@dftest.options(include_dtypes=[int])\n",
        "def dftest_positive(col, df):\n",
        "  return df[col].apply(lambda x: x > 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfAVHk-DD-Aw",
        "outputId": "38b9bf20-756a-460d-eb30-fb0db900c0ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Get the results"
      ],
      "metadata": {
        "id": "pKjsYCC_RJXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --dataframe example.csv --files tests.py --print --graph validity"
      ],
      "metadata": {
        "id": "ckMaiqCHMMeF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8090b0c-fd3c-4f9d-d468-d1c5a0384a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_positive — D)\n",
            "\u001b[F\u001b[KTesting 20% (#2: dftest_positive — B)\n",
            "\u001b[F\u001b[KTesting 40% (#3: dftest_positive — A)\n",
            "\u001b[F\u001b[KTesting 60% (#4: dftest_positive — C)\n",
            "\u001b[F\u001b[KTesting 80% (#5: dftest_positive — Index)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "Columns Tested: 5/6 (83%).\n",
            "Columns valid: 2/5 (40.0%).\n",
            "\n",
            "--- Column 1: Index ---\n",
            "Test #01: dftest_positive — Index: 99/100 (99.0%).\n",
            "   Index\n",
            "0      0\n",
            "\n",
            "--- Column 2: A ---\n",
            "Test #01: dftest_positive — A: 99/100 (99.0%).\n",
            "    Index  A\n",
            "21     21  0\n",
            "\n",
            "--- Column 3: B ---\n",
            "Test #01: dftest_positive — B: 94/100 (94.0%).\n",
            "   Index   B\n",
            "0      0 -90\n",
            "1      1 -39\n",
            "2      2 -33\n",
            "3      3 -89\n",
            "4      4 -85\n",
            "5      5 -43\n",
            "\n",
            "<Figure size 640x480 with 2 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: understanding the graphs"
      ],
      "metadata": {
        "id": "VnLGwB14Rs5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the different shades and the numbers of the columns in the heatmap, instead of the previous clear green bar, as well as the details for each invalid row in the printing.\n",
        "\n",
        "If no boolean tests were run, the heatmap generated will be more detailed and place columns on a gradient instead of a binary success-fail.\n",
        "\n"
      ],
      "metadata": {
        "id": "zfn6pnJGWFR9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Error sparsity**\n",
        "\n",
        "The final bar in the graph represents the dataframe. You can compare it to the individual columns to get a sense of the overlap between failed test; the more overlap, the closer it will be to the actual column values; the less, the lower."
      ],
      "metadata": {
        "id": "PanPWjRSEdsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting binary graph back.**\n",
        "\n",
        "It's possible to get the binary heatmap back by specifying validity-binary as the graph parameter. In this case, success of a row will be determined by the portion of its rows that are valid - by default requiring all of them, but this can be specified when adding the test."
      ],
      "metadata": {
        "id": "buG5fTTFENqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Any columns that has at least one nonpositive is red\n",
        "!dftest --dataframe example.csv --files tests.py --print --graph validity-binary"
      ],
      "metadata": {
        "id": "-OQD_QAmchQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d92007a5-b782-437e-8b9c-35a3f22741f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_positive — D)\n",
            "\u001b[F\u001b[KTesting 20% (#2: dftest_positive — C)\n",
            "\u001b[F\u001b[KTesting 40% (#3: dftest_positive — Index)\n",
            "\u001b[F\u001b[KTesting 60% (#4: dftest_positive — A)\n",
            "\u001b[F\u001b[KTesting 80% (#5: dftest_positive — B)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "Columns Tested: 5/6 (83%).\n",
            "Columns valid: 2/5 (40.0%).\n",
            "\n",
            "--- Column 1: Index ---\n",
            "Test #01: dftest_positive — Index: 99/100 (99.0%).\n",
            "   Index\n",
            "0      0\n",
            "\n",
            "--- Column 2: A ---\n",
            "Test #01: dftest_positive — A: 99/100 (99.0%).\n",
            "    Index  A\n",
            "21     21  0\n",
            "\n",
            "--- Column 3: B ---\n",
            "Test #01: dftest_positive — B: 94/100 (94.0%).\n",
            "   Index   B\n",
            "0      0 -90\n",
            "1      1 -39\n",
            "2      2 -33\n",
            "3      3 -89\n",
            "4      4 -85\n",
            "5      5 -43\n",
            "\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests.py\n",
        "import dftest\n",
        "\n",
        "@dftest.options(include_dtypes=[int], success_threshold=0.95)\n",
        "def dftest_positive(col, df):\n",
        "  return df[col].apply(lambda x: x > 0)"
      ],
      "metadata": {
        "id": "xD11gNMIcnli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d4baf61-457a-4f22-b1c0-24442730aeda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Any columns that has at least 5% nonpositives is red\n",
        "!dftest --dataframe example.csv --files tests.py --print --graph validity-binary"
      ],
      "metadata": {
        "id": "q-WkkoCSfA4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7f65070-f4fb-4b61-a524-154c4855713a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_positive — B)\n",
            "\u001b[F\u001b[KTesting 20% (#2: dftest_positive — A)\n",
            "\u001b[F\u001b[KTesting 40% (#3: dftest_positive — Index)\n",
            "\u001b[F\u001b[KTesting 60% (#4: dftest_positive — D)\n",
            "\u001b[F\u001b[KTesting 80% (#5: dftest_positive — C)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "Columns Tested: 5/6 (83%).\n",
            "Columns valid: 4/5 (80.0%).\n",
            "\n",
            "--- Column 3: B ---\n",
            "Test #01: dftest_positive — B: 94/100 (94.0%).\n",
            "   Index   B\n",
            "0      0 -90\n",
            "1      1 -39\n",
            "2      2 -33\n",
            "3      3 -89\n",
            "4      4 -85\n",
            "5      5 -43\n",
            "\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can force the non-binary graph even if you have both boolean and index tests. In this case, only index tests will be charted."
      ],
      "metadata": {
        "id": "MmpbRBqIHkjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests.py\n",
        "import dftest\n",
        "\n",
        "@dftest.options(include_dtypes=[int], success_threshold=0.95)\n",
        "def dftest_positive(col, df):\n",
        "  return df[col].apply(lambda x: x > 0)\n",
        "\n",
        "@dftest.options(include_dtypes=[object])\n",
        "def dftest_before_n(col, df):\n",
        "  return sum(1 for cell in df[col] if ord(cell) < 110)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN09LWA1H55y",
        "outputId": "59ba8968-3ec0-4134-8a32-68c24d05a56c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Only the positive test will show up in the graph\n",
        "!dftest --dataframe example.csv --files tests.py --print --graph validity-nonbinary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX9HpwdHH3YY",
        "outputId": "a1046ccc-6144-47c3-fba9-9ff7b5e91afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_before_n — E)\n",
            "\u001b[F\u001b[KTesting 17% (#2: dftest_positive — B)\n",
            "\u001b[F\u001b[KTesting 33% (#3: dftest_positive — Index)\n",
            "\u001b[F\u001b[KTesting 50% (#4: dftest_positive — D)\n",
            "\u001b[F\u001b[KTesting 67% (#5: dftest_positive — A)\n",
            "\u001b[F\u001b[KTesting 83% (#6: dftest_positive — C)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "Columns Tested: 6/6 (100%).\n",
            "Columns valid: 5/6 (83.33%).\n",
            "\n",
            "--- Column 3: B ---\n",
            "Test #01: dftest_positive — B: 94/100 (94.0%).\n",
            "   Index   B\n",
            "0      0 -90\n",
            "1      1 -39\n",
            "2      2 -33\n",
            "3      3 -89\n",
            "4      4 -85\n",
            "5      5 -43\n",
            "\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ּStep 4: playing with invalid rows"
      ],
      "metadata": {
        "id": "G-cdx5YOY3ml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"demonstration-4\"></a>\n",
        "## Demonstration 4: Coverage "
      ],
      "metadata": {
        "id": "BHB2jGaWeS_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 0: about coverage"
      ],
      "metadata": {
        "id": "ZQ7OVFkTdh0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The intended us eof this tool can be analogous to traditional unit testing. In the same way that it's useful not only to see which parts of the code produce unexpected results, but also which parts of the code are not running when they should (or vice versa), it is useful to us to see both which parts of our data are invalid, as well as which parts of the data are not even being tested. \n",
        "\n",
        "Below is a minimal scenario denmonstarting this possible usefulness.\n",
        "\n",
        "As a sidenote, in unit testing the term for checking which parts are being tested vs. untested is _coverage_, and it's the same term I'll use her."
      ],
      "metadata": {
        "id": "2MxIz5k08wx7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Adding nulls"
      ],
      "metadata": {
        "id": "-kNaMSBRdtQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's put some null values into the dataframe and see what our tests give us."
      ],
      "metadata": {
        "id": "Hy_2mB2NdtdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('example.csv')\n",
        "df.loc[:5, 'C'] = None\n",
        "df.to_csv('example.csv', index=False)"
      ],
      "metadata": {
        "id": "m6sw_YI_Aa1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Rerunning the tests"
      ],
      "metadata": {
        "id": "bChoJdQAeDWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --dataframe example.csv --files tests.py --print --graph validity"
      ],
      "metadata": {
        "id": "WYi1svXDePpj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19637e0c-c462-4ccf-dcc9-9b40cb9db7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_before_n — E)\n",
            "\u001b[F\u001b[KTesting 20% (#2: dftest_positive — B)\n",
            "\u001b[F\u001b[KTesting 40% (#3: dftest_positive — D)\n",
            "\u001b[F\u001b[KTesting 60% (#4: dftest_positive — A)\n",
            "\u001b[F\u001b[KTesting 80% (#5: dftest_positive — Index)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "Columns Tested: 5/6 (83%).\n",
            "Columns valid: 4/5 (80.0%).\n",
            "\n",
            "--- Column 3: B ---\n",
            "Test #01: dftest_positive — B: 94/100 (94.0%).\n",
            "   Index   B\n",
            "0      0 -90\n",
            "1      1 -39\n",
            "2      2 -33\n",
            "3      3 -89\n",
            "4      4 -85\n",
            "5      5 -43\n",
            "\n",
            "<Figure size 640x480 with 2 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see that instead of showing C as invalid, it shows it lacking coverage. Why is that?\n"
      ],
      "metadata": {
        "id": "oetQyk1dXRrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Investigate"
      ],
      "metadata": {
        "id": "4DyjSHfZeTwH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "An obvious step is to look at the column's values:"
      ],
      "metadata": {
        "id": "t99aBPBAeWnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['C']"
      ],
      "metadata": {
        "id": "TVDv8fqedE2n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f0094a-0fc4-4894-ffe8-839b15aff88b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      NaN\n",
              "1      NaN\n",
              "2      NaN\n",
              "3      NaN\n",
              "4      NaN\n",
              "      ... \n",
              "95    18.0\n",
              "96    69.0\n",
              "97    16.0\n",
              "98    72.0\n",
              "99    69.0\n",
              "Name: C, Length: 100, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that pandas converted the column into float, to allow for Nan types. Thus, `df.select_dtypes(int)` does not detect it, and it is not detected.\n",
        "\n",
        "This is a pretty trivial thing to notice, but we might not have had we not seen the column's lack of coverage, and instead gotten tangled in our own code if this ever came to bite us."
      ],
      "metadata": {
        "id": "ib4hR8YUdkKU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"demonstration-6\"></a>\n",
        "## Demonstration 5: handling Exceptions"
      ],
      "metadata": {
        "id": "yDvfBLA8eyej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Will this cause an exception?"
      ],
      "metadata": {
        "id": "glFkOj8iw2wc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In demonstration 4, the invalid values caused pandas to generalize the type of the column, which hid it from our tests. What would have happened if we picked our columns manually, instead of by type (hence forcing the test over our invalid cells)?"
      ],
      "metadata": {
        "id": "j2Mc5lWtrZVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests.py\n",
        "import dftest\n",
        "\n",
        "@dftest.options(exclude=['E'])\n",
        "def dftest_positive(col, df):\n",
        "  return df[col].apply(lambda x: x > 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8OY9XNxLAZ2",
        "outputId": "e08e5dbc-5bb3-48e6-959a-e8afa50c0ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --dataframe example.csv --files tests.py"
      ],
      "metadata": {
        "id": "TBHmTixZsMiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6188e460-e502-4a17-de35-4b1b6d930ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_positive — B)\n",
            "\u001b[F\u001b[KTesting 20% (#2: dftest_positive — D)\n",
            "\u001b[F\u001b[KTesting 40% (#3: dftest_positive — C)\n",
            "\u001b[F\u001b[KTesting 60% (#4: dftest_positive — Index)\n",
            "\u001b[F\u001b[KTesting 80% (#5: dftest_positive — A)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "Columns Tested: 5/6 (83%).\n",
            "Columns valid: 1/5 (20.0%).\n",
            "\n",
            "--- Column 1: Index ---\n",
            "Test #01: dftest_positive — Index: 99/100 (99.0%).\n",
            "   Index\n",
            "0      0\n",
            "\n",
            "--- Column 2: A ---\n",
            "Test #01: dftest_positive — A: 99/100 (99.0%).\n",
            "    Index  A\n",
            "21     21  0\n",
            "\n",
            "--- Column 3: B ---\n",
            "Test #01: dftest_positive — B: 94/100 (94.0%).\n",
            "   Index   B\n",
            "0      0 -90\n",
            "1      1 -39\n",
            "2      2 -33\n",
            "3      3 -89\n",
            "4      4 -85\n",
            "5      5 -43\n",
            "\n",
            "--- Column 4: C ---\n",
            "Test #01: dftest_positive — C: 94/100 (94.0%).\n",
            "   Index   C\n",
            "0      0 NaN\n",
            "1      1 NaN\n",
            "2      2 NaN\n",
            "3      3 NaN\n",
            "4      4 NaN\n",
            "5      5 NaN\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Will _this_ cause an exception?"
      ],
      "metadata": {
        "id": "Gi0FE0_uw9aR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notably, the test runs pretty smoothly. This is because pandas uses NaNs to represent missing values, rather than Nones, allowing traditional numerical tests to run on them (always returning `False`).\n",
        "\n",
        "What would happen if we tried to put a string in, though?"
      ],
      "metadata": {
        "id": "v-6k2UAotOPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('example.csv')\n",
        "df.loc[:5, 'A'] = 'invalid'\n",
        "df.to_csv('example.csv', index=False)"
      ],
      "metadata": {
        "id": "D0TA5EkRthBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "A5ZBv8OAt2kH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "c88c0658-9386-4848-c136-d6384468e5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-90cdb6bf-ef88-4580-a0e6-b89bbecaf661\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>invalid</td>\n",
              "      <td>-90</td>\n",
              "      <td>NaN</td>\n",
              "      <td>55</td>\n",
              "      <td>k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>invalid</td>\n",
              "      <td>-39</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>invalid</td>\n",
              "      <td>-33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>59</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>invalid</td>\n",
              "      <td>-89</td>\n",
              "      <td>NaN</td>\n",
              "      <td>47</td>\n",
              "      <td>j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>invalid</td>\n",
              "      <td>-85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>62</td>\n",
              "      <td>f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>18</td>\n",
              "      <td>80</td>\n",
              "      <td>18.0</td>\n",
              "      <td>83</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>7</td>\n",
              "      <td>84</td>\n",
              "      <td>69.0</td>\n",
              "      <td>19</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>55</td>\n",
              "      <td>20</td>\n",
              "      <td>16.0</td>\n",
              "      <td>40</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>11</td>\n",
              "      <td>99</td>\n",
              "      <td>72.0</td>\n",
              "      <td>28</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>71</td>\n",
              "      <td>96</td>\n",
              "      <td>69.0</td>\n",
              "      <td>42</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90cdb6bf-ef88-4580-a0e6-b89bbecaf661')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90cdb6bf-ef88-4580-a0e6-b89bbecaf661 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90cdb6bf-ef88-4580-a0e6-b89bbecaf661');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Index        A   B     C   D  E\n",
              "0       0  invalid -90   NaN  55  k\n",
              "1       1  invalid -39   NaN  44  n\n",
              "2       2  invalid -33   NaN  59  d\n",
              "3       3  invalid -89   NaN  47  j\n",
              "4       4  invalid -85   NaN  62  f\n",
              "..    ...      ...  ..   ...  .. ..\n",
              "95     95       18  80  18.0  83  c\n",
              "96     96        7  84  69.0  19  p\n",
              "97     97       55  20  16.0  40  u\n",
              "98     98       11  99  72.0  28  d\n",
              "99     99       71  96  69.0  42  c\n",
              "\n",
              "[100 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --dataframe example.csv --files tests.py"
      ],
      "metadata": {
        "id": "HBPoS3hNtwfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b277a2d8-0c5d-4309-d412-b6bfea536b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_positive — Index)\n",
            "\u001b[F\u001b[KTesting 20% (#2: dftest_positive — C)\n",
            "\u001b[F\u001b[KTesting 40% (#3: dftest_positive — D)\n",
            "\u001b[F\u001b[KTesting 60% (#4: dftest_positive — A)\n",
            "\u001b[F\u001b[KTraceback (most recent call last):\n",
            "  File \"/usr/local/bin/dftest\", line 95, in <module>\n",
            "    results = dftests.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/dftest/DFTests.py\", line 294, in run\n",
            "    results.append(test.run(self.dataframe))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/dftest/Test.py\", line 107, in run\n",
            "    result, columns_tested = self.test(dataframe)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/dftest/Test.py\", line 74, in test\n",
            "    return self.predicate(test_target, **self.kwargs), self.tested_columns.difference(self.ignore_columns)\n",
            "  File \"tests.py\", line 5, in dftest_positive\n",
            "    return df[col].apply(lambda x: x > 0)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\", line 4357, in apply\n",
            "    return SeriesApply(self, func, convert_dtype, args, kwargs).apply()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\", line 1043, in apply\n",
            "    return self.apply_standard()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\", line 1101, in apply_standard\n",
            "    convert=self.convert_dtype,\n",
            "  File \"pandas/_libs/lib.pyx\", line 2859, in pandas._libs.lib.map_infer\n",
            "  File \"tests.py\", line 5, in <lambda>\n",
            "    return df[col].apply(lambda x: x > 0)\n",
            "TypeError: '>' not supported between instances of 'str' and 'int'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As one might expect, an exception is thrown.\n"
      ],
      "metadata": {
        "id": "ImkNA4TBuE_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Handling exceptions"
      ],
      "metadata": {
        "id": "2Q_rLPHZxHtf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`dftest` does not make any assumptoins on the desired behaviour in edge cases, so it is up to the user to catch any exceptions their test might raise. \n",
        "\n",
        "Below is a simple example which will flag any non-number values as invalid."
      ],
      "metadata": {
        "id": "QSRIUnRmxLw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests.py\n",
        "import dftest\n",
        "\n",
        "@dftest.options(exclude=['E'])\n",
        "def dftest_positive(column, dataframe):\n",
        "  return dataframe[column] \\\n",
        "  .apply(lambda x: x if isinstance(x, int) or isinstance(x, float) else -1) \\\n",
        "  .apply(lambda x: x > 0)"
      ],
      "metadata": {
        "id": "pREN5REVuYi5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "798ccd78-903b-482e-8c90-e161c56c76fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --dataframe example.csv --files tests.py"
      ],
      "metadata": {
        "id": "J1GZl-xAttBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c80f77d6-7f7b-4e99-8942-45a56f61d271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_positive — Index)\n",
            "\u001b[F\u001b[KTesting 20% (#2: dftest_positive — A)\n",
            "\u001b[F\u001b[KTesting 40% (#3: dftest_positive — C)\n",
            "\u001b[F\u001b[KTesting 60% (#4: dftest_positive — D)\n",
            "\u001b[F\u001b[KTesting 80% (#5: dftest_positive — B)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "Columns Tested: 5/6 (83%).\n",
            "Columns valid: 1/5 (20.0%).\n",
            "\n",
            "--- Column 1: Index ---\n",
            "Test #01: dftest_positive — Index: 99/100 (99.0%).\n",
            "   Index\n",
            "0      0\n",
            "\n",
            "--- Column 2: A ---\n",
            "Test #01: dftest_positive — A: 0/100 (0.0%).\n",
            "   Index        A\n",
            "0      0  invalid\n",
            "1      1  invalid\n",
            "2      2  invalid\n",
            "3      3  invalid\n",
            "4      4  invalid\n",
            "5      5  invalid\n",
            "6      6       80\n",
            "7      7       17\n",
            "8      8       26\n",
            "9      9       47\n",
            "...\n",
            "\n",
            "--- Column 3: B ---\n",
            "Test #01: dftest_positive — B: 94/100 (94.0%).\n",
            "   Index   B\n",
            "0      0 -90\n",
            "1      1 -39\n",
            "2      2 -33\n",
            "3      3 -89\n",
            "4      4 -85\n",
            "5      5 -43\n",
            "\n",
            "--- Column 4: C ---\n",
            "Test #01: dftest_positive — C: 94/100 (94.0%).\n",
            "   Index   C\n",
            "0      0 NaN\n",
            "1      1 NaN\n",
            "2      2 NaN\n",
            "3      3 NaN\n",
            "4      4 NaN\n",
            "5      5 NaN\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Demonstration 6: the `tests` submodule"
      ],
      "metadata": {
        "id": "J2Ocsh8FZ7eu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 0: What is the `tests` submodule?"
      ],
      "metadata": {
        "id": "zMX0ijvHgT8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`dftests.tests` is a submodule contaning many useful functions to generate common tests, like regex comparisons, numeric range checks and many more. They help remove a lot of boilerplate code and can significantly simplify the process of creating tests.\n",
        "\n",
        "In addition to the test \"makers\", there are also a number of normal tests. \n",
        "\n",
        "Currently, all of the normal tests are generic Index test."
      ],
      "metadata": {
        "id": "FsJFlPLzgZGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: A new dataframe"
      ],
      "metadata": {
        "id": "DKp6tbeeMBW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this demonstration, let's look at the following dataframe"
      ],
      "metadata": {
        "id": "ysx-PBB8hsez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    'A': [1    , 2   , True , 3    , 4      , 'a'  ], # Integers\n",
        "    'B': ['Yes', 'No', 'Yes', 'No' , 'Maybe', 'No' ], # Yes/No boolean \n",
        "    'C': [20   , 45  , 100  , None , 20     , 0    ], # Percentages\n",
        "    'D': [55   , -1  , 100  , 60   , 120    , 76   ], # Percentages\n",
        "    'E': [0.243, 0.2 , 0.33 , 1.2  , 0.1    , 0    ], # 0-1 fractions\n",
        "    'F': ['66.17.230.185', '238.122.190.60', 'ERROR', '129.167.214.X', '217.110.194.132', '106.121.183.215'] # IP addresses\n",
        "}) \n",
        "df.to_csv('example.csv')"
      ],
      "metadata": {
        "id": "3YFevo2Uanx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: How to configure tests?"
      ],
      "metadata": {
        "id": "wjjDXplthJ8Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unlike previous demonstratoins, we will not be defining the functions in place; rather, generating them roughly like so:\n",
        "\n",
        "```python\n",
        "dftest_mytest = tests.make_test(options)\n",
        "```\n",
        "Or alternatively, straight importing them:\n",
        "```python\n",
        "from dftest.tests import dftest_positive\n",
        "```\n",
        "\n",
        "The `dftest` command simply searches for callable attributes with the right prefix, so it will detect both of these, even the import.\n",
        "\n",
        "Notably though, we cannot use the `options` decorator to configure our tests, as they are not defined using `def`. Instead. the function `dftests.declare_options` may be ran with the test as the first parameter.\n",
        "\n"
      ],
      "metadata": {
        "id": "MzOGken9it13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Add tests"
      ],
      "metadata": {
        "id": "1eBsaSGjqhQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing cells are \"Yes\" or \"No\" (in list)"
      ],
      "metadata": {
        "id": "BHTZTIaUqkxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`in_list_test` generates a test that checks values in a column are in a given list"
      ],
      "metadata": {
        "id": "Zhm5t3xVaKZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests.py\n",
        "from dftest import tests, declare_options\n",
        "\n",
        "dftest_yes_or_no = tests.in_list_test(['yes', 'no', 'Yes', 'No'])\n",
        "declare_options(dftest_yes_or_no, include=['B'])\n",
        "\n"
      ],
      "metadata": {
        "id": "ilmJBl8saUjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2213acfe-f062-4c11-b7c6-b5cf05d0f338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing cells are balid IP addresses (match regex)"
      ],
      "metadata": {
        "id": "KBl4eSz4qpuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`match_test` generates test that checks values match a given regex."
      ],
      "metadata": {
        "id": "aYT1qqnTc83e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a tests.py\n",
        "dftest_ip_addr = tests.match_test(r'([0-9]{1,3}\\.){3}[0-9]{1,3}')\n",
        "declare_options(dftest_ip_addr, include=['F'])\n",
        "\n"
      ],
      "metadata": {
        "id": "HtVJx8H-dkj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dcd53ee-052a-403a-d17f-eb0e4cc41205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing cells are not errors (nonequal)"
      ],
      "metadata": {
        "id": "z2dFT9XpqxRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`non_equal_test` generates tests that check values aren't equal to some value"
      ],
      "metadata": {
        "id": "eiH16jTmeNjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a tests.py\n",
        "dftest_no_errors = tests.non_equal_test('ERROR')\n",
        "declare_options(dftest_no_errors, include=['F'])\n",
        "\n"
      ],
      "metadata": {
        "id": "hrecF-Oueaxf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a189a4-3c68-438d-d5b7-d6b9d1bf2c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing numerical cells are in range"
      ],
      "metadata": {
        "id": "jQiTmUr5q8bM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`range_test` generates tests that check values are in a certain (bound or unbound) range. \n",
        "\n",
        "`is_fraction` is a range test that checks a value is between 0 and 1. `is_positive` checks values are a above 0. "
      ],
      "metadata": {
        "id": "4LgHyIrtfR2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a tests.py\n",
        "\n",
        "from dftest.tests import dftest_fraction\n",
        "dftest_percent = tests.in_range_test(0, 100, left_inclusive=True, right_inclusive=True)\n",
        "\n",
        "declare_options(dftest_percent, include=['C', 'D'])\n",
        "declare_options(tests.dftest_fraction, include=['E'])\n",
        "\n"
      ],
      "metadata": {
        "id": "fT0h-CM2fXX7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2df1708-a2de-423b-c760-45072133971e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Type checking"
      ],
      "metadata": {
        "id": "QnbCdhrarVOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`simple_type_test` generates a test that checks values are of a given type. `is_float`, `is_integer` and `is_str` are existing common derivations of it"
      ],
      "metadata": {
        "id": "Ya3TsvuNhu2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a tests.py\n",
        "\n",
        "dftest_integer = tests.simple_type_test(int)\n",
        "\n",
        "from dftest.tests import dftest_float, dftest_str\n",
        "\n",
        "declare_options(dftest_integer, include=['C', 'D'])\n",
        "declare_options(tests.dftest_float, include=['E'])\n",
        "declare_options(tests.dftest_str, include=['B', 'F'])\n",
        "\n"
      ],
      "metadata": {
        "id": "9X6dd4oknLzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "189ef03c-abd4-4564-f087-f06004c7dda8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Null checking"
      ],
      "metadata": {
        "id": "kQXgU1ZDrbLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`is_not_null` checks values are not `None` or `NaN`"
      ],
      "metadata": {
        "id": "KhinpMBJs7XA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a tests.py\n",
        "from dftest.tests import dftest_not_null"
      ],
      "metadata": {
        "id": "pQTg8qFPta-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60863243-119d-4482-cd13-6e1e54c7b9dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Run!"
      ],
      "metadata": {
        "id": "L2PmaJf9rd6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --dataframe example.csv --files tests.py"
      ],
      "metadata": {
        "id": "FQ-ZIb_nttGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ead83d07-62e0-4e97-daab-3ca601295a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: Type float — E)\n",
            "\u001b[F\u001b[KTesting 06% (#2: In range [0, 1] — E)\n",
            "\u001b[F\u001b[KTesting 11% (#3: Type int — C)\n",
            "\u001b[F\u001b[KTesting 17% (#4: Type int — D)\n",
            "\u001b[F\u001b[KTesting 22% (#5: Match /([0-9]{1,3}\\.){3}[0-9]{1,3}/ — F)\n",
            "\u001b[F\u001b[KTesting 28% (#6: Not ERROR — F)\n",
            "\u001b[F\u001b[KTesting 33% (#7: dftest_not_null — A)\n",
            "\u001b[F\u001b[KTesting 39% (#8: dftest_not_null — C)\n",
            "\u001b[F\u001b[KTesting 44% (#9: dftest_not_null — E)\n",
            "\u001b[F\u001b[KTesting 50% (#10: dftest_not_null — F)\n",
            "\u001b[F\u001b[KTesting 56% (#11: dftest_not_null — D)\n",
            "\u001b[F\u001b[KTesting 61% (#12: dftest_not_null — B)\n",
            "\u001b[F\u001b[KTesting 67% (#13: dftest_not_null — Unnamed: 0)\n",
            "\u001b[F\u001b[KTesting 72% (#14: In range [0, 100] — C)\n",
            "\u001b[F\u001b[KTesting 78% (#15: In range [0, 100] — D)\n",
            "\u001b[F\u001b[KTesting 83% (#16: Type str — F)\n",
            "\u001b[F\u001b[KTesting 89% (#17: Type str — B)\n",
            "\u001b[F\u001b[KTesting 94% (#18: In list ['yes', 'no', 'Yes', 'No'] — B)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "Columns Tested: 7/7 (100%).\n",
            "Columns valid: 2/7 (28.57%).\n",
            "\n",
            "--- Column 3: B ---\n",
            "Test #01: dftest_not_null — B: 6/6 (100.0%).\n",
            "\n",
            "Test #02: Type str — B: 6/6 (100.0%).\n",
            "\n",
            "Test #03: In list ['yes', 'no', 'Yes', 'No'] — B: 5/6 (83.33%).\n",
            "   Unnamed: 0      B\n",
            "4           4  Maybe\n",
            "\n",
            "--- Column 4: C ---\n",
            "Test #01: Type int — C: 0/6 (0.0%).\n",
            "   Unnamed: 0      C\n",
            "0           0   20.0\n",
            "1           1   45.0\n",
            "2           2  100.0\n",
            "3           3    NaN\n",
            "4           4   20.0\n",
            "5           5    0.0\n",
            "\n",
            "Test #02: In range [0, 100] — C: 5/6 (83.33%).\n",
            "   Unnamed: 0   C\n",
            "3           3 NaN\n",
            "\n",
            "--- Column 5: D ---\n",
            "Test #01: Type int — D: 6/6 (100.0%).\n",
            "\n",
            "Test #02: In range [0, 100] — D: 4/6 (66.67%).\n",
            "   Unnamed: 0    D\n",
            "1           1   -1\n",
            "4           4  120\n",
            "\n",
            "--- Column 6: E ---\n",
            "Test #01: Type float — E: 6/6 (100.0%).\n",
            "\n",
            "Test #02: In range [0, 1] — E: 5/6 (83.33%).\n",
            "   Unnamed: 0    E\n",
            "3           3  1.2\n",
            "\n",
            "--- Column 7: F ---\n",
            "Test #01: Match /([0-9]{1,3}\\.){3}[0-9]{1,3}/ — F: 4/6 (66.67%).\n",
            "   Unnamed: 0              F\n",
            "2           2          ERROR\n",
            "3           3  129.167.214.X\n",
            "\n",
            "Test #02: Not ERROR — F: 5/6 (83.33%).\n",
            "   Unnamed: 0      F\n",
            "2           2  ERROR\n",
            "\n",
            "Test #03: Type str — F: 6/6 (100.0%).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demonstration 7: column autodetection"
      ],
      "metadata": {
        "id": "rfNpXZaetROM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 0: Setup - Composed IDs"
      ],
      "metadata": {
        "id": "VCXzLHucTwY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's imagine a database which includes some column detailing years, some column detailing names and some ID column which should be the year number followed by a dash and the corresponding entry name."
      ],
      "metadata": {
        "id": "WlbLZLbhJmIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLQzYAvJMdbd",
        "outputId": "6c0048b4-8cb2-41e9-8170-85bf147b7279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: names in /usr/local/lib/python3.7/dist-packages (0.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import names, random\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df['Year'] = [random.randint(2000, 2020) for i in range(100)]\n",
        "df['Name'] = [names.get_full_name() for i in range(100)]\n",
        "df.insert(0, 'ID', [f'{year}-{name.replace(\" \", \"\")}' for year, name in zip(df['Year'], df['Name'])])\n",
        "df.to_csv('example.csv', index=False)\n",
        "pd.read_csv('example.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "sH9ZlYmAJ0mn",
        "outputId": "e8956874-b409-4acb-a5b4-5997b7533e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-414992f7-b82b-4867-8e6c-77233278b806\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Year</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-JohnCser</td>\n",
              "      <td>2015</td>\n",
              "      <td>John Cser</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-ErnestWoods</td>\n",
              "      <td>2010</td>\n",
              "      <td>Ernest Woods</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2008-DavidBernard</td>\n",
              "      <td>2008</td>\n",
              "      <td>David Bernard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-BrandyMassey</td>\n",
              "      <td>2013</td>\n",
              "      <td>Brandy Massey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-EarlCaldwell</td>\n",
              "      <td>2016</td>\n",
              "      <td>Earl Caldwell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>2020-KevinHensley</td>\n",
              "      <td>2020</td>\n",
              "      <td>Kevin Hensley</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>2015-MargaritaWooley</td>\n",
              "      <td>2015</td>\n",
              "      <td>Margarita Wooley</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>2007-CarmenStallings</td>\n",
              "      <td>2007</td>\n",
              "      <td>Carmen Stallings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>2002-JoyEliezrie</td>\n",
              "      <td>2002</td>\n",
              "      <td>Joy Eliezrie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>2010-MeaganSultemeier</td>\n",
              "      <td>2010</td>\n",
              "      <td>Meagan Sultemeier</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-414992f7-b82b-4867-8e6c-77233278b806')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-414992f7-b82b-4867-8e6c-77233278b806 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-414992f7-b82b-4867-8e6c-77233278b806');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                       ID  Year               Name\n",
              "0           2015-JohnCser  2015          John Cser\n",
              "1        2010-ErnestWoods  2010       Ernest Woods\n",
              "2       2008-DavidBernard  2008      David Bernard\n",
              "3       2013-BrandyMassey  2013      Brandy Massey\n",
              "4       2016-EarlCaldwell  2016      Earl Caldwell\n",
              "..                    ...   ...                ...\n",
              "95      2020-KevinHensley  2020      Kevin Hensley\n",
              "96   2015-MargaritaWooley  2015   Margarita Wooley\n",
              "97   2007-CarmenStallings  2007   Carmen Stallings\n",
              "98       2002-JoyEliezrie  2002       Joy Eliezrie\n",
              "99  2010-MeaganSultemeier  2010  Meagan Sultemeier\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Testing IDs"
      ],
      "metadata": {
        "id": "M7K4ti2AT0Ey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say we'd like to test for malformed IDs."
      ],
      "metadata": {
        "id": "HVC_-22AOZny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests.py\n",
        "import numpy as np\n",
        "from dftest import options\n",
        "\n",
        "def dftest_id_form(dataframe):\n",
        "  generated_ids =  dataframe['Year'].apply(str) + np.tile('-', 100) + dataframe['Name'].apply(lambda x: x.replace(' ', ''))\n",
        "  return dataframe['ID'] == generated_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcQxkZiwOebl",
        "outputId": "38a5851c-ffe5-4573-c586-26fdc0f8efa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --dataframe example.csv --files tests.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_RmIhUnP-NY",
        "outputId": "9fce155c-b3ab-4ead-9af3-d4106096f86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_id_form)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "Columns Tested: 3/3 (100%).\n",
            "Columns valid: 3/3 (100.0%).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Columns autodected"
      ],
      "metadata": {
        "id": "S7x17YzWT_W1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Putting in some invalid values:"
      ],
      "metadata": {
        "id": "nBXOL2IqSt6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[:5, 'ID'] = 'invalid'\n",
        "df.to_csv('example.csv', index=False)"
      ],
      "metadata": {
        "id": "EG5rhGwOSw3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --dataframe example.csv --files tests.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjBZ2E7YS_kz",
        "outputId": "8fb65856-109b-4794-84eb-04461d81342a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_id_form)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "Columns Tested: 3/3 (100%).\n",
            "Columns valid: 0/3 (0.0%).\n",
            "\n",
            "--- Column 1: ID ---\n",
            "Test #01: dftest_id_form: 94/100 (94.0%).\n",
            "        ID\n",
            "0  invalid\n",
            "1  invalid\n",
            "2  invalid\n",
            "3  invalid\n",
            "4  invalid\n",
            "5  invalid\n",
            "\n",
            "--- Column 2: Year ---\n",
            "Test #01: dftest_id_form: 94/100 (94.0%).\n",
            "        ID  Year\n",
            "0  invalid  2015\n",
            "1  invalid  2010\n",
            "2  invalid  2008\n",
            "3  invalid  2013\n",
            "4  invalid  2016\n",
            "5  invalid  2011\n",
            "\n",
            "--- Column 3: Name ---\n",
            "Test #01: dftest_id_form: 94/100 (94.0%).\n",
            "        ID              Name\n",
            "0  invalid         John Cser\n",
            "1  invalid      Ernest Woods\n",
            "2  invalid     David Bernard\n",
            "3  invalid     Brandy Massey\n",
            "4  invalid     Earl Caldwell\n",
            "5  invalid  Elizabeth Roemer\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the results for all three columns accessed. This is, in fact, one of the main features `dftest`; it can detect automatically which columns you are testing.\n",
        "\n",
        "This feature generalizes to any columns accessed by `loc`, `iloc`, `__getitem__`, or attributes, via both DataFrame and Series. "
      ],
      "metadata": {
        "id": "_TDtWqc0TtDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Overriding Autodetection"
      ],
      "metadata": {
        "id": "rkqvXyKiUQgb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the case dlineated above, we quite possibly don't actually think of our test as testing ID, Year and Name, but rather only testing ID, assuming Name and Year are valid.\n",
        "\n",
        "In that case, we'll probably want to avoid the autodetction of Name and Year. We can do this by the `ignore_columns` and `columns_tested` options.\n"
      ],
      "metadata": {
        "id": "ZFniT3OZGRUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests.py\n",
        "import numpy as np\n",
        "from dftest import options\n",
        "\n",
        "@options(ignore_columns=['Year', 'Name']) # Specify columns autodetection should ignore\n",
        "def dftest_id_form(dataframe):\n",
        "  generated_ids =  dataframe['Year'].apply(str) + np.tile('-', 100) + dataframe['Name'].apply(lambda x: x.replace(' ', ''))\n",
        "  return dataframe['ID'] == generated_ids"
      ],
      "metadata": {
        "id": "eeiJhSHjYyll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "970b62f8-ca8f-4f26-84fc-1884175220f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests.py\n",
        "import numpy as np\n",
        "from dftest import options\n",
        "\n",
        "@options(tested_columns=['ID']) # Specify columns autodetection should ignore\n",
        "def dftest_id_form(dataframe):\n",
        "  generated_ids =  dataframe['Year'].apply(str) + np.tile('-', 100) + dataframe['Name'].apply(lambda x: x.replace(' ', ''))\n",
        "  return dataframe['ID'] == generated_ids"
      ],
      "metadata": {
        "id": "Wx98kwHrZFFH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c5b6dc-315f-4141-8e9d-31456d6004ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --dataframe example.csv --files tests.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9nW877aars4",
        "outputId": "1fff0c0d-a906-43bc-ce3b-5c8b2c81363e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_id_form)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "Columns Tested: 1/3 (33%).\n",
            "Columns valid: 0/1 (0.0%).\n",
            "\n",
            "--- Column 1: ID ---\n",
            "Test #01: dftest_id_form: 94/100 (94.0%).\n",
            "        ID\n",
            "0  invalid\n",
            "1  invalid\n",
            "2  invalid\n",
            "3  invalid\n",
            "4  invalid\n",
            "5  invalid\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `tested_columns` is only available for \"concrete\" tests that run over specific columns.\n",
        "\n",
        "For genreic tests, we can turn off autodetection by specifying `column_autodetect=False`. In that case, each test will be assigned to the column it is applied to, only."
      ],
      "metadata": {
        "id": "9TjPM_zDY79G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Edge cases"
      ],
      "metadata": {
        "id": "nyd9abGOV4nf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In some edge cases autodetection may not work properly; particularly when dealing with multiple dataframes.\n",
        "\n",
        "Under the hood, the library tracks calls to `pandas.Index.__getitem__` which is called by all of the aforementioned methods.\n",
        "\n",
        "however, there is no way to ensure that the calling object is the tested dataframe. Even if we compared the tested dataframe with the original caller, the test functions themselves may modify, add or slice the dataframe in ways that are completely valid, yet create a new object, all before actually acessing the column.\n",
        "\n",
        "For this reason, if a column in a different dataframe is accessed, and that column has the same name as a column in the tested dataframe, that column of the tested dataframe will be autodetected.\n",
        "\n",
        "As an example, let's say that the `Year` and `Name` coulumns are actually taken from some other dataframe, `some_origin_dataset.csv`, and that our actual tested dataframe, with the ID generated from that origin dataset, also has its own `Year` column, with Years 1900-1920."
      ],
      "metadata": {
        "id": "q0TPKMHsiKe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import names, random\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df['Year'] = [random.randint(2000, 2020) for i in range(100)]\n",
        "df['Name'] = [names.get_full_name() for i in range(100)]\n",
        "df.to_csv('some_origin_dataset.csv', index=False)\n",
        "\n",
        "df2 = pd.DataFrame()\n",
        "df2['ID'] = [f'{year}-{name.replace(\" \", \"\")}' for year, name in zip(df['Year'], df['Name'])]\n",
        "df2['Year'] = [random.randint(1900, 1920) for i in range(100)]\n",
        "\n",
        "df2.loc[:5, 'ID'] = 'invalid'\n",
        "df2.to_csv('example.csv', index=False)\n",
        "\n",
        "print(df)\n",
        "print(df2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8q4DRKMkCW9",
        "outputId": "a40f4496-3303-447d-ae5a-77927e32139c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Year             Name\n",
            "0   2001     Larry Cowart\n",
            "1   2008   Bianca Mcguire\n",
            "2   2008  Lottie Mcarthur\n",
            "3   2005     Martin Smith\n",
            "4   2019       Doris Reed\n",
            "..   ...              ...\n",
            "95  2011     Roger Jodoin\n",
            "96  2018     Charles Cone\n",
            "97  2009  Gregory Rodgers\n",
            "98  2009      Boyd Rogers\n",
            "99  2013      Dawn Dexter\n",
            "\n",
            "[100 rows x 2 columns]\n",
            "                     ID  Year\n",
            "0               invalid  1918\n",
            "1               invalid  1909\n",
            "2               invalid  1915\n",
            "3               invalid  1918\n",
            "4               invalid  1900\n",
            "..                  ...   ...\n",
            "95     2011-RogerJodoin  1911\n",
            "96     2018-CharlesCone  1902\n",
            "97  2009-GregoryRodgers  1904\n",
            "98      2009-BoydRogers  1916\n",
            "99      2013-DawnDexter  1902\n",
            "\n",
            "[100 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Farthermore, let's remove the options decorator, letting the columns be autododetected."
      ],
      "metadata": {
        "id": "gHMIv-BOoAR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from dftest import options\n",
        "\n",
        "def dftest_id_form(dataframe):\n",
        "  origin_df = pd.read_csv('some_origin_dataset.csv')\n",
        "  generated_ids =  origin_df['Year'].apply(str) + np.tile('-', 100) + origin_df['Name'].apply(lambda x: x.replace(' ', ''))\n",
        "  return dataframe['ID'] == generated_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zNunTXOkmIs",
        "outputId": "4ae4defc-9c2f-4a02-fea7-97d3dde06aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --dataframe example.csv --files tests.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzbFD7z1lwgU",
        "outputId": "d2b3e092-87ef-408a-98b6-2dae5765b939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_id_form)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "Columns Tested: 2/2 (100%).\n",
            "Columns valid: 0/2 (0.0%).\n",
            "\n",
            "--- Column 1: ID ---\n",
            "Test #01: dftest_id_form: 94/100 (94.0%).\n",
            "        ID\n",
            "0  invalid\n",
            "1  invalid\n",
            "2  invalid\n",
            "3  invalid\n",
            "4  invalid\n",
            "5  invalid\n",
            "\n",
            "--- Column 2: Year ---\n",
            "Test #01: dftest_id_form: 94/100 (94.0%).\n",
            "        ID  Year\n",
            "0  invalid  1918\n",
            "1  invalid  1909\n",
            "2  invalid  1915\n",
            "3  invalid  1918\n",
            "4  invalid  1900\n",
            "5  invalid  1912\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In that case, we can see that the `Year` column in the tested dataframe, which we in fact did not do anything with, was detected as a tested column. What happened was that the call `origin_df['Year']` was detected, and `'Year'` was determined as a valid column name from the tested dataframe; thus `dftest` registered it as a tested column.\n",
        "\n",
        "A relatively simple way to avoid this is to just specify the `ignore_columns` options, but this behaviour is important to keep in mind."
      ],
      "metadata": {
        "id": "m6M7VSG2oJAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demonstration 8: divergent tests"
      ],
      "metadata": {
        "id": "euiyX-Y2UGi4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 0: Divergent Tests?"
      ],
      "metadata": {
        "id": "eBairqjouLCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both the type of the test result (Index vs. Boolean) and the columns that were tested (see Demonstration 7) are determined at runtime. This means we can a make a test that conditionally returns more information, and that if a test conditionally accesses columns, the columns that will show up as tested and covered would only be the ones it *actually* accessed at runtime."
      ],
      "metadata": {
        "id": "YnB7vvWxWyOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: A result-divergent test"
      ],
      "metadata": {
        "id": "NZnk6vcAuNci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As an example, we may want to get more detailed error report, only if there are errors beyond a certain threshold, and otherwise we'd to not waste processing time and just return a valid/invalid binary.\n",
        "\n",
        "the following test checks a sample of 300 rows for cells outside the unit interval, and only if it finds more than 15 it will see it important enough to tell exactly which lines; otherwise it will just mark the test succesful. "
      ],
      "metadata": {
        "id": "DBoe5xb9rK6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests.py\n",
        "\n",
        "def dftest_unit_interval(col, df):\n",
        "  sample_errors = sum(1 for cell in df.sample(300)[col] if not 0 <= cell <= 1)\n",
        "  if sample_errors >= 15:\n",
        "    return df[col].apply(lambda x: 0 <= x <= 1)\n",
        "  return True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L11P8beds4u-",
        "outputId": "9a0f2104-9808-4cfa-85f5-d4933d6d0a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tests.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running it on an example dataset"
      ],
      "metadata": {
        "id": "6RfkGRmhuZ2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df =  pd.DataFrame(np.random.randint(0, 100, size=(1000, 4))/100, columns=list('ABCD'))\n",
        "df['B'][:200] *= 120\n",
        "df['C'][:10] *= 120\n",
        "\n",
        "df.to_csv('example.csv', index=False)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "bSI_tbi3sSlS",
        "outputId": "a5369dc1-b62d-482a-9d10-b60b9e57f603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-608ecc04-f5a9-439c-8764-5f1fee606995\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.90</td>\n",
              "      <td>8.40</td>\n",
              "      <td>104.40</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.56</td>\n",
              "      <td>22.80</td>\n",
              "      <td>69.60</td>\n",
              "      <td>0.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.21</td>\n",
              "      <td>28.80</td>\n",
              "      <td>102.00</td>\n",
              "      <td>0.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.45</td>\n",
              "      <td>16.80</td>\n",
              "      <td>44.40</td>\n",
              "      <td>0.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.41</td>\n",
              "      <td>92.40</td>\n",
              "      <td>34.80</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0.92</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>0.77</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0.37</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>0.49</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-608ecc04-f5a9-439c-8764-5f1fee606995')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-608ecc04-f5a9-439c-8764-5f1fee606995 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-608ecc04-f5a9-439c-8764-5f1fee606995');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        A      B       C     D\n",
              "0    0.90   8.40  104.40  0.75\n",
              "1    0.56  22.80   69.60  0.82\n",
              "2    0.21  28.80  102.00  0.26\n",
              "3    0.45  16.80   44.40  0.34\n",
              "4    0.41  92.40   34.80  0.55\n",
              "..    ...    ...     ...   ...\n",
              "995  0.92   0.57    0.31  0.06\n",
              "996  0.77   0.64    0.51  0.85\n",
              "997  0.37   0.91    0.76  0.59\n",
              "998  0.25   0.95    0.97  0.99\n",
              "999  0.49   0.14    0.35  0.35\n",
              "\n",
              "[1000 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dftest --dataframe example.csv --files tests.py --column B\n",
        "!dftest --dataframe example.csv --files tests.py --column C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHE96CNyuddq",
        "outputId": "454e0f1b-3ebb-4364-a8b9-7cc9f5532ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 00% (#1: dftest_unit_interval — B)\n",
            "\u001b[F\u001b[KTesting 25% (#2: dftest_unit_interval — C)\n",
            "\u001b[F\u001b[KTesting 50% (#3: dftest_unit_interval — A)\n",
            "\u001b[F\u001b[KTesting 75% (#4: dftest_unit_interval — D)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "--- B ---\n",
            "Test #01: dftest_unit_interval — B: 801/1000 (80.1%).\n",
            "      B\n",
            "0   8.4\n",
            "1  22.8\n",
            "2  28.8\n",
            "3  16.8\n",
            "4  92.4\n",
            "5  76.8\n",
            "6  61.2\n",
            "7  21.6\n",
            "8  37.2\n",
            "9  20.4\n",
            "...\n",
            "\n",
            "Testing 00% (#1: dftest_unit_interval — A)\n",
            "\u001b[F\u001b[KTesting 25% (#2: dftest_unit_interval — C)\n",
            "\u001b[F\u001b[KTesting 50% (#3: dftest_unit_interval — B)\n",
            "\u001b[F\u001b[KTesting 75% (#4: dftest_unit_interval — D)\n",
            "\u001b[F\u001b[KFinished testing\n",
            "--- C ---\n",
            "Test #01: dftest_unit_interval — C: Success\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: A column-divergent test"
      ],
      "metadata": {
        "id": "xCMMLH_9vdxx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a second example, let's say we have a dataset where, by an old standard, an item's ID was a hash of the `fullname` column, but since 2015 that standard was changed such that an ID is a `yymmdd` formatting of the `CreationTimestamp` column. We want to test this behavior\n",
        "\n",
        "Our function may look something like this:"
      ],
      "metadata": {
        "id": "ltP9dLQUvwAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests.py\n",
        "from datetime import datetime\n",
        "\n",
        "def dftest_id(dataframe):\n",
        "  creation_times =  dataframe['CreationTimestamp'].apply(datetime.fromtimestamp)\n",
        "  return \\\n",
        "    creation_times >= 2018 and dataframe['ID'] == creation_times.apply(lambda x: x.strftime('%y%m%d')) \\\n",
        "    or creation_times < 2018 and dataframe['ID'] == dataframe['fullname'].apply(hash)"
      ],
      "metadata": {
        "id": "RxRUeBMlxUu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that due to the short circuiting nature of python `fullname` would only be accessed if there are creation times."
      ],
      "metadata": {
        "id": "rA3QriujJr0y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On a normal run, all `fullname`, `CreationTimestamp` and `ID` would all be autodected. However, imagine we have a different dataframe for each year. In that case, we would see a loss of coverage immediately following the standard change, as `fullname` would no longer be accessed and thus detected."
      ],
      "metadata": {
        "id": "FTzYbjAROQPh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demonstration 11: styling output graphs "
      ],
      "metadata": {
        "id": "Ov02-kWDVBSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can set the colorscheme graphs use to communicate validity using a JSON file.\n",
        "\n",
        "A color scheme is just a list of color-number pairs, with numbers starting from 0 and ending in 1. The corresponding colors for 0 and 1 are used for binary invalid/valid data. Continous data may be classified (in the tests success grah for individual columns) to the color with the lower smaller or equal value, or mapped to a gradient generated from the list.\n",
        "\n",
        "Thus, the default style looks like so:\n",
        "```json\n",
        "[\n",
        "  {\"red\": 0},\n",
        "  {\"orange\": 0.25}\n",
        "  {\"yellow\": 0.5}\n",
        "  {\"blue\": 0.75}\n",
        "  {\"green\": 1}\n",
        "]\n",
        "```\n",
        "\n",
        "colors don't have to be equally spaced.\n",
        "\n",
        "Colorschemes like shown above should be paired with a column name, so \n",
        "```json\n",
        "  \"Object Number\": [\n",
        "    {\"purple\": 0},\n",
        "    {\"red\": 0.5},\n",
        "    {\"yellow\": 1}\n",
        "  ]\n",
        "```\n",
        "will make graphs for the \"Object Number\" column display in the specified colorscheme.\n",
        "\n",
        "You can use the special name `__DEFAULT__` to assign default color schemes, and the special name `__DATAFRAME__` to assign colorschemes to dataframe graphs.\n",
        "\n",
        "The following style file will color dataframe graphs in monochrome, switch orange and blue for all columns but A, and reduce A to an uneven red-green-blue scheme:"
      ],
      "metadata": {
        "id": "1nKoMTFpPTNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile style.json\n",
        "{\n",
        "  \"__DATAFRAME__\": [\n",
        "    {\"white\": 0},\n",
        "    {\"lightgray\": 0.25},\n",
        "    {\"silver\": 0.5},\n",
        "    {\"darkgray\": 0.75},\n",
        "    {\"black\": 1}\n",
        "  ],\n",
        "\n",
        "  \"__DEFAULT__\": [\n",
        "    {\"red\": 0},\n",
        "    {\"blue\": 0.25},\n",
        "    {\"yellow\": 0.5},\n",
        "    {\"orange\": 0.75},\n",
        "    {\"green\": 1}\n",
        "  ],\n",
        "\n",
        "  \"A\": [\n",
        "    {\"red\": 0},\n",
        "    {\"green\": 0.75},\n",
        "    {\"blue\": 1}\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "PeWCLwMcVb4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can specify a style file to use with the `--style` option."
      ],
      "metadata": {
        "id": "GzOvh4bUU1WA"
      }
    }
  ]
}